Traceback (most recent call last):
  File "mainwb.py", line 242, in <module>
    main()
  File "mainwb.py", line 235, in main
    model, loader, args)
  File "mainwb.py", line 127, in life_experience
    loss = model.observe(Variable(v_x), Variable(v_y), task_info["task"])
  File "/notebooks/exp_lamaml/model/lamaml.py", line 108, in observe
    fast_weights = self.inner_update(batch_x, fast_weights, batch_y, t)
  File "/notebooks/exp_lamaml/model/lamaml.py", line 55, in inner_update
    grads = torch.autograd.grad(loss, fast_weights, create_graph=graph_required, retain_graph=graph_required)
  File "/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py", line 149, in grad
    inputs, allow_unused)
RuntimeError: One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
